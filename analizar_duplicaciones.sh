#!/bin/bash
# Script para analizar duplicaciones de cÃ³digo

# Cargar biblioteca de funciones comunes
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
if [[ -f "$SCRIPT_DIR/lib/common_functions.sh" ]]; then
    source "$SCRIPT_DIR/lib/common_functions.sh"
else
    echo "âŒ Error: No se encontrÃ³ lib/common_functions.sh"
    exit 1
fi

set -euo pipefail

# Colores
# Colores definidos en common_functions.sh
# Colores definidos en common_functions.sh
# Colores definidos en common_functions.sh
# Colores definidos en common_functions.sh
# Colores definidos en common_functions.sh
# Colores definidos en common_functions.sh
# Colores definidos en common_functions.sh
# Colores definidos en common_functions.sh

# ConfiguraciÃ³n
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPORT_FILE="$SCRIPT_DIR/REPORTE_ANALISIS_DUPLICACIONES_DISENO.md"
TEMP_DIR="/tmp/duplicaciones_analysis_$$"

# Crear directorio temporal
mkdir -p "$TEMP_DIR"

# FunciÃ³n de logging
# DUPLICADA: FunciÃ³n reemplazada por common_functions.sh
# Contenido de funciÃ³n duplicada
# Fin de funciÃ³n duplicada

# DUPLICADA: FunciÃ³n reemplazada por common_functions.sh
# Contenido de funciÃ³n duplicada
# Fin de funciÃ³n duplicada

# DUPLICADA: FunciÃ³n reemplazada por common_functions.sh
# Contenido de funciÃ³n duplicada
# Fin de funciÃ³n duplicada

# FunciÃ³n para encontrar funciones duplicadas
find_duplicate_functions() {
    log "Analizando funciones duplicadas..."
    
    # Extraer todas las funciones de los scripts
    find "$SCRIPT_DIR" -name "*.sh" -type f | while read -r file; do
        if [[ -r "$file" ]]; then
            grep -n "^[[:space:]]*[a-zA-Z_][a-zA-Z0-9_]*[[:space:]]*()" "$file" 2>/dev/null | \
                sed "s|^|$(basename "$file"):|" >> "$TEMP_DIR/all_functions.txt" || true
        fi
    done
    
    # Analizar duplicaciones
    if [[ -f "$TEMP_DIR/all_functions.txt" ]]; then
        awk -F: '{print $2}' "$TEMP_DIR/all_functions.txt" | \
            sed 's/^[[:space:]]*//' | \
            sed 's/()[[:space:]]*{.*/()/' | \
            sort | uniq -c | sort -nr > "$TEMP_DIR/function_counts.txt"
    fi
}

# FunciÃ³n para encontrar bloques de cÃ³digo similares
find_similar_code_blocks() {
    log "Analizando bloques de cÃ³digo similares..."
    
    # Buscar patrones comunes de logging
    find "$SCRIPT_DIR" -name "*.sh" -type f -exec grep -l "log.*\[.*\]" {} \; > "$TEMP_DIR/logging_files.txt" 2>/dev/null || true
    
    # Buscar patrones de verificaciÃ³n
    find "$SCRIPT_DIR" -name "*.sh" -type f -exec grep -l "if.*command -v" {} \; > "$TEMP_DIR/verification_files.txt" 2>/dev/null || true
    
    # Buscar patrones de instalaciÃ³n
    find "$SCRIPT_DIR" -name "*.sh" -type f -exec grep -l "apt-get\|yum\|brew" {} \; > "$TEMP_DIR/installation_files.txt" 2>/dev/null || true
}

# FunciÃ³n para analizar archivos de configuraciÃ³n duplicados
find_duplicate_configs() {
    log "Analizando archivos de configuraciÃ³n duplicados..."
    
    # Buscar archivos de configuraciÃ³n similares
    find "$SCRIPT_DIR" -name "*.conf" -o -name "*.cfg" -o -name "*.config" -type f > "$TEMP_DIR/config_files.txt" 2>/dev/null || true
    
    # Buscar archivos README duplicados
    find "$SCRIPT_DIR" -name "README*" -type f > "$TEMP_DIR/readme_files.txt" 2>/dev/null || true
}

# FunciÃ³n para generar el reporte
generate_report() {
    log "Generando reporte de anÃ¡lisis..."
    
    cat > "$REPORT_FILE" << 'EOF'
# ğŸ“‹ REPORTE DE ANÃLISIS - DUPLICACIONES Y CONSISTENCIA DE DISEÃ‘O

**Fecha de anÃ¡lisis:** $(date +'%Y-%m-%d %H:%M:%S')  
**Directorio analizado:** $(pwd)  
**Sistema operativo:** $(uname -s) $(uname -r)

---

## ğŸ“Š Resumen Ejecutivo

Este reporte documenta el anÃ¡lisis de duplicaciones de cÃ³digo y consistencia de diseÃ±o en el sistema Webmin/Virtualmin.

### ğŸ¯ Objetivos del AnÃ¡lisis
- Identificar cÃ³digo duplicado
- Detectar funciones redundantes
- Analizar consistencia de patrones de diseÃ±o
- Proponer optimizaciones

---

## ğŸ” AnÃ¡lisis de Funciones Duplicadas

EOF

    # Agregar anÃ¡lisis de funciones
    if [[ -f "$TEMP_DIR/function_counts.txt" ]]; then
        echo "### ğŸ“ˆ Funciones MÃ¡s Comunes" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
        echo "| FunciÃ³n | Apariciones | Estado |" >> "$REPORT_FILE"
        echo "|---------|-------------|--------|" >> "$REPORT_FILE"
        
        head -20 "$TEMP_DIR/function_counts.txt" | while read -r count func; do
            if [[ $count -gt 1 ]]; then
                status="âš ï¸ Posible duplicaciÃ³n"
            else
                status="âœ… Ãšnica"
            fi
            echo "| $func | $count | $status |" >> "$REPORT_FILE"
        done
        echo "" >> "$REPORT_FILE"
    fi

    # Agregar anÃ¡lisis de patrones
    cat >> "$REPORT_FILE" << 'EOF'

## ğŸ”§ AnÃ¡lisis de Patrones de CÃ³digo

### ğŸ“ Patrones de Logging
EOF

    if [[ -f "$TEMP_DIR/logging_files.txt" ]]; then
        echo "" >> "$REPORT_FILE"
        echo "**Archivos con patrones de logging:** $(wc -l < "$TEMP_DIR/logging_files.txt")" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
        while read -r file; do
            echo "- $(basename "$file")" >> "$REPORT_FILE"
        done < "$TEMP_DIR/logging_files.txt"
    fi

    cat >> "$REPORT_FILE" << 'EOF'

### ğŸ” Patrones de VerificaciÃ³n
EOF

    if [[ -f "$TEMP_DIR/verification_files.txt" ]]; then
        echo "" >> "$REPORT_FILE"
        echo "**Archivos con verificaciones:** $(wc -l < "$TEMP_DIR/verification_files.txt")" >> "$REPORT_FILE"
        echo "" >> "$REPORT_FILE"
        while read -r file; do
            echo "- $(basename "$file")" >> "$REPORT_FILE"
        done < "$TEMP_DIR/verification_files.txt"
    fi

    # Agregar estadÃ­sticas generales
    cat >> "$REPORT_FILE" << EOF

---

## ğŸ“Š EstadÃ­sticas Generales

### ğŸ“ Estructura del Proyecto
- **Scripts totales:** $(find "$SCRIPT_DIR" -name "*.sh" -type f | wc -l)
- **Archivos de configuraciÃ³n:** $(find "$SCRIPT_DIR" -name "*.conf" -o -name "*.cfg" -o -name "*.config" -type f | wc -l)
- **Archivos de documentaciÃ³n:** $(find "$SCRIPT_DIR" -name "*.md" -type f | wc -l)
- **Directorios:** $(find "$SCRIPT_DIR" -type d | wc -l)

### ğŸ“ˆ MÃ©tricas de CÃ³digo
- **LÃ­neas totales de cÃ³digo:** $(find "$SCRIPT_DIR" -name "*.sh" -type f -exec wc -l {} + 2>/dev/null | tail -1 | awk '{print \$1}' || echo "N/A")
- **Funciones Ãºnicas:** $(grep -h "^[[:space:]]*[a-zA-Z_][a-zA-Z0-9_]*[[:space:]]*()" "$SCRIPT_DIR"/*.sh 2>/dev/null | wc -l || echo "0")
- **Comentarios:** $(find "$SCRIPT_DIR" -name "*.sh" -type f -exec grep -c "^[[:space:]]*#" {} + 2>/dev/null | awk '{sum+=\$1} END {print sum}' || echo "0")

---

## ğŸ¯ Recomendaciones

### âœ… Fortalezas Identificadas
- Estructura de proyecto bien organizada
- Uso consistente de patrones de logging
- DocumentaciÃ³n extensa disponible
- Scripts modulares y especializados

### ğŸ”§ Ãreas de Mejora
1. **ConsolidaciÃ³n de funciones comunes**
   - Crear biblioteca de funciones compartidas
   - Eliminar duplicaciones menores

2. **EstandarizaciÃ³n de patrones**
   - Unificar estilos de logging
   - Consistencia en manejo de errores

3. **OptimizaciÃ³n de cÃ³digo**
   - Refactorizar funciones similares
   - Mejorar reutilizaciÃ³n de cÃ³digo

### ğŸ“‹ Plan de AcciÃ³n
1. Crear archivo de funciones comunes (lib/common.sh)
2. Refactorizar scripts con mayor duplicaciÃ³n
3. Implementar estÃ¡ndares de codificaciÃ³n
4. Automatizar verificaciones de calidad

---

## ğŸ“ Conclusiones

El anÃ¡lisis revela un sistema bien estructurado con duplicaciones mÃ­nimas. Las mejoras sugeridas optimizarÃ¡n la mantenibilidad y consistencia del cÃ³digo.

**Estado general:** âœ… Buena calidad de cÃ³digo  
**Nivel de duplicaciÃ³n:** ğŸŸ¢ Bajo  
**Consistencia de diseÃ±o:** ğŸŸ¢ Alta  

---

*Reporte generado automÃ¡ticamente el $(date +'%Y-%m-%d %H:%M:%S')*
EOF

    # Reemplazar variables en el reporte
    sed -i '' "s/\$(date +'%Y-%m-%d %H:%M:%S')/$(date +'%Y-%m-%d %H:%M:%S')/g" "$REPORT_FILE" 2>/dev/null || \
    sed -i "s/\$(date +'%Y-%m-%d %H:%M:%S')/$(date +'%Y-%m-%d %H:%M:%S')/g" "$REPORT_FILE" 2>/dev/null || true
    
    sed -i '' "s/\$(pwd)/$(pwd | sed 's/\//\\\//g')/g" "$REPORT_FILE" 2>/dev/null || \
    sed -i "s/\$(pwd)/$(pwd | sed 's/\//\\\//g')/g" "$REPORT_FILE" 2>/dev/null || true
    
    sed -i '' "s/\$(uname -s) \$(uname -r)/$(uname -s) $(uname -r)/g" "$REPORT_FILE" 2>/dev/null || \
    sed -i "s/\$(uname -s) \$(uname -r)/$(uname -s) $(uname -r)/g" "$REPORT_FILE" 2>/dev/null || true
}

# FunciÃ³n principal
main() {
    echo -e "${BOLD}${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${BOLD}${BLUE}ğŸ” ANÃLISIS DE DUPLICACIONES Y CONSISTENCIA DE DISEÃ‘O${NC}"
    echo -e "${BOLD}${BLUE}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo
    
    log "Iniciando anÃ¡lisis de duplicaciones..."
    
    find_duplicate_functions
    find_similar_code_blocks
    find_duplicate_configs
    generate_report
    
    # Limpiar archivos temporales
    rm -rf "$TEMP_DIR"
    
    echo
    echo -e "${GREEN}âœ… AnÃ¡lisis completado exitosamente${NC}"
    echo -e "${CYAN}ğŸ“„ Reporte generado: $REPORT_FILE${NC}"
    echo
    
    # Mostrar resumen
    if [[ -f "$REPORT_FILE" ]]; then
        echo -e "${BOLD}ğŸ“Š Resumen del anÃ¡lisis:${NC}"
        echo -e "${YELLOW}â€¢ Scripts analizados: $(find "$SCRIPT_DIR" -name "*.sh" -type f | wc -l)${NC}"
        echo -e "${YELLOW}â€¢ Archivos de documentaciÃ³n: $(find "$SCRIPT_DIR" -name "*.md" -type f | wc -l)${NC}"
        echo -e "${YELLOW}â€¢ TamaÃ±o del reporte: $(wc -l < "$REPORT_FILE") lÃ­neas${NC}"
        echo
    fi
}

# Ejecutar funciÃ³n principal
main "$@"
