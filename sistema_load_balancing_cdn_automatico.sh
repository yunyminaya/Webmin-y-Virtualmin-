#!/bin/bash

# =============================================================================
# SISTEMA DE LOAD BALANCING Y CDN AUTOM√ÅTICO
# Load balancing inteligente + CDN distribuido para millones de usuarios
# Auto-scaling geogr√°fico y failover autom√°tico
# =============================================================================

set -euo pipefail

# Cargar biblioteca de funciones comunes
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
if [[ -f "$SCRIPT_DIR/lib/common_functions.sh" ]]; then
    source "$SCRIPT_DIR/lib/common_functions.sh"
else
    echo "‚ùå Error: No se encontr√≥ lib/common_functions.sh"
    exit 1
fi

# Variables globales
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
LOG_FILE="/var/log/load_balancing_cdn_${TIMESTAMP}.log"
CONFIG_DIR="/etc/load-balancing-cdn"
LB_INSTANCES=4
BACKEND_SERVERS=8
EDGE_LOCATIONS=12

# Inicializar logging
init_logging "load_balancing_cdn"

# Banner principal
show_banner() {
    clear
    cat << 'EOF'
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë  üåê SISTEMA DE LOAD BALANCING Y CDN AUTOM√ÅTICO                              ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  ‚ö° CARACTER√çSTICAS:                                                          ‚ïë
‚ïë  ‚Ä¢ HAProxy + Nginx Load Balancing                                           ‚ïë
‚ïë  ‚Ä¢ CDN Edge Locations distribuidas                                          ‚ïë
‚ïë  ‚Ä¢ Auto-scaling geogr√°fico                                                  ‚ïë
‚ïë  ‚Ä¢ Failover autom√°tico < 3 segundos                                         ‚ïë
‚ïë  ‚Ä¢ Health checks avanzados                                                  ‚ïë
‚ïë  ‚Ä¢ SSL termination distribuido                                              ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  üéØ CAPACIDAD:                                                               ‚ïë
‚ïë  ‚Ä¢ >10 millones requests/minuto                                             ‚ïë
‚ïë  ‚Ä¢ >100TB/d√≠a de transferencia                                              ‚ïë
‚ïë  ‚Ä¢ Latencia < 50ms global                                                   ‚ïë
‚ïë  ‚Ä¢ 99.99% uptime garantizado                                                ‚ïë
‚ïë  ‚Ä¢ Auto-scaling en tiempo real                                              ‚ïë
‚ïë                                                                              ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
EOF
    echo
}

# Configurar HAProxy para load balancing extremo
configure_haproxy_extreme() {
    log_step "1" "Configurando HAProxy para load balancing extremo"
    
    create_secure_dir "$CONFIG_DIR/haproxy"
    create_secure_dir "/var/lib/haproxy"
    
    # Configuraci√≥n principal de HAProxy
    cat > "$CONFIG_DIR/haproxy/haproxy.cfg" << 'EOF'
global
    daemon
    user haproxy
    group haproxy
    chroot /var/lib/haproxy
    pidfile /var/run/haproxy.pid
    maxconn 1000000
    
    # Multi-threading para m√°ximo rendimiento
    nbthread 16
    cpu-map auto:1/1-16 0-15
    
    # SSL optimizations
    ssl-default-bind-ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384
    ssl-default-bind-options ssl-min-ver TLSv1.2
    ssl-default-server-ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384
    ssl-default-server-options ssl-min-ver TLSv1.2
    
    # Logging
    log stdout local0 info
    
    # Stats socket para monitoring
    stats socket /var/run/haproxy.sock mode 600 level admin
    stats timeout 30s
    
    # Lua scripts para l√≥gica avanzada
    lua-load /etc/haproxy/lua/geo_routing.lua
    lua-load /etc/haproxy/lua/rate_limiting.lua
    lua-load /etc/haproxy/lua/health_check.lua

defaults
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms
    timeout http-keep-alive 30s
    timeout http-request 10s
    timeout queue 5s
    
    # Error handling
    errorfile 400 /etc/haproxy/errors/400.http
    errorfile 403 /etc/haproxy/errors/403.http
    errorfile 408 /etc/haproxy/errors/408.http
    errorfile 500 /etc/haproxy/errors/500.http
    errorfile 502 /etc/haproxy/errors/502.http
    errorfile 503 /etc/haproxy/errors/503.http
    errorfile 504 /etc/haproxy/errors/504.http
    
    # Compression
    compression algo gzip
    compression type text/css text/html text/javascript text/plain text/xml application/javascript application/json
    
    # Logging
    option httplog
    option dontlognull
    option log-health-checks

# Stats interface
listen stats
    bind *:8080
    stats enable
    stats uri /haproxy-stats
    stats realm HAProxy\ Statistics
    stats auth admin:$(openssl rand -base64 12)
    stats refresh 30s
    stats show-legends
    stats show-node

# Frontend for HTTP traffic
frontend http_frontend
    bind *:80
    bind *:443 ssl crt /etc/ssl/certs/
    
    # Rate limiting por IP
    stick-table type ip size 1m expire 10m store gpc0,http_req_rate(10s)
    http-request track-sc0 src
    http-request deny if { sc_get_gpc0(0) gt 0 }
    http-request set-var(req.rate_limit) lua.rate_limit
    http-request deny if { var(req.rate_limit) -m bool }
    
    # DDoS protection
    http-request deny if { src_get_gpc0() gt 20 }
    
    # Geographic routing
    http-request set-var(req.geo_region) lua.get_geo_region
    
    # Security headers
    http-response add-header X-Frame-Options SAMEORIGIN
    http-response add-header X-Content-Type-Options nosniff
    http-response add-header X-XSS-Protection "1; mode=block"
    http-response add-header Strict-Transport-Security "max-age=31536000; includeSubDomains"
    
    # Redirect HTTP to HTTPS
    redirect scheme https code 301 if !{ ssl_fc }
    
    # Load balancing based on content type
    use_backend api_servers if { path_beg /api/ }
    use_backend static_servers if { path_reg \.(css|js|img|jpg|png|gif|ico|svg|woff|woff2|ttf|eot)$ }
    use_backend wordpress_servers if { hdr(host) -i wordpress. }
    use_backend laravel_servers if { hdr(host) -i laravel. }
    
    # Default backend
    default_backend web_servers

# Backend for API servers
backend api_servers
    balance roundrobin
    option httpchk GET /api/health
    http-check expect status 200
    
    # Sticky sessions for APIs que lo requieran
    cookie SERVERID insert indirect nocache
    
    # Servers with different weights based on capacity
    server api1 10.0.1.10:80 check weight 100 cookie api1
    server api2 10.0.1.11:80 check weight 100 cookie api2
    server api3 10.0.1.12:80 check weight 100 cookie api3
    server api4 10.0.1.13:80 check weight 100 cookie api4
    
    # Backup servers
    server api_backup1 10.0.2.10:80 check backup weight 50
    server api_backup2 10.0.2.11:80 check backup weight 50

# Backend for static content servers
backend static_servers
    balance uri
    hash-type consistent
    option httpchk HEAD /
    
    # Long cache headers for static content
    http-response add-header Cache-Control "public, max-age=31536000, immutable"
    
    server static1 10.0.3.10:80 check weight 100
    server static2 10.0.3.11:80 check weight 100
    server static3 10.0.3.12:80 check weight 100
    server static4 10.0.3.13:80 check weight 100

# Backend for WordPress servers
backend wordpress_servers
    balance leastconn
    option httpchk GET /wp-admin/admin-ajax.php
    http-check send meth POST uri /wp-admin/admin-ajax.php body "action=heartbeat"
    http-check expect status 200
    
    # WordPress specific optimizations
    compression algo gzip
    compression type text/css text/html text/javascript application/javascript
    
    # Session persistence for logged users
    stick-table type string len 32 size 30k expire 30m
    stick on cookie(wordpress_logged_in)
    
    server wp1 10.0.4.10:80 check inter 2s fall 3 rise 2 weight 100
    server wp2 10.0.4.11:80 check inter 2s fall 3 rise 2 weight 100
    server wp3 10.0.4.12:80 check inter 2s fall 3 rise 2 weight 100
    server wp4 10.0.4.13:80 check inter 2s fall 3 rise 2 weight 100

# Backend for Laravel servers
backend laravel_servers
    balance leastconn
    option httpchk GET /health
    http-check expect string "ok"
    
    # Laravel session handling
    stick-table type string len 40 size 30k expire 120m
    stick on cookie(laravel_session)
    
    server laravel1 10.0.5.10:80 check inter 2s fall 3 rise 2 weight 100
    server laravel2 10.0.5.11:80 check inter 2s fall 3 rise 2 weight 100
    server laravel3 10.0.5.12:80 check inter 2s fall 3 rise 2 weight 100
    server laravel4 10.0.5.13:80 check inter 2s fall 3 rise 2 weight 100

# Default web servers backend
backend web_servers
    balance leastconn
    option httpchk GET /health
    
    server web1 10.0.6.10:80 check inter 5s fall 3 rise 2 weight 100
    server web2 10.0.6.11:80 check inter 5s fall 3 rise 2 weight 100
    server web3 10.0.6.12:80 check inter 5s fall 3 rise 2 weight 100
    server web4 10.0.6.13:80 check inter 5s fall 3 rise 2 weight 100
    server web5 10.0.6.14:80 check inter 5s fall 3 rise 2 weight 100
    server web6 10.0.6.15:80 check inter 5s fall 3 rise 2 weight 100
    server web7 10.0.6.16:80 check inter 5s fall 3 rise 2 weight 100
    server web8 10.0.6.17:80 check inter 5s fall 3 rise 2 weight 100
EOF

    # Crear scripts Lua para l√≥gica avanzada
    create_secure_dir "$CONFIG_DIR/haproxy/lua"
    
    # Script de routing geogr√°fico
    cat > "$CONFIG_DIR/haproxy/lua/geo_routing.lua" << 'EOF'
-- Geographic routing based on IP address
function get_geo_region(txn)
    local ip = txn.sf:src()
    
    -- Simple IP to region mapping (en producci√≥n usar GeoIP database)
    local ip_num = ip2num(ip)
    
    -- Rangos de ejemplo (actualizar con rangos reales)
    if ip_num >= ip2num("1.0.0.0") and ip_num <= ip2num("50.255.255.255") then
        return "us-east"
    elseif ip_num >= ip2num("51.0.0.0") and ip_num <= ip2num("100.255.255.255") then
        return "us-west"
    elseif ip_num >= ip2num("101.0.0.0") and ip_num <= ip2num("150.255.255.255") then
        return "europe"
    elseif ip_num >= ip2num("151.0.0.0") and ip_num <= ip2num("200.255.255.255") then
        return "asia"
    else
        return "global"
    end
end

function ip2num(ip)
    local num = 0
    for octet in string.gmatch(ip, "%d+") do
        num = num * 256 + tonumber(octet)
    end
    return num
end

core.register_fetches("get_geo_region", get_geo_region)
EOF

    # Script de rate limiting inteligente
    cat > "$CONFIG_DIR/haproxy/lua/rate_limiting.lua" << 'EOF'
-- Intelligent rate limiting
function rate_limit(txn)
    local ip = txn.sf:src()
    local ua = txn.http:req_get_headers()["user-agent"]
    local path = txn.sf:path()
    
    -- Rate limits por tipo de contenido
    local limits = {
        api = 1000,     -- 1000 req/min para APIs
        static = 10000, -- 10000 req/min para archivos est√°ticos
        dynamic = 500   -- 500 req/min para contenido din√°mico
    }
    
    local content_type = "dynamic"
    
    if string.match(path, "^/api/") then
        content_type = "api"
    elseif string.match(path, "%.(css|js|png|jpg|gif|ico)$") then
        content_type = "static"
    end
    
    -- Obtener contador actual del stick table
    local current_rate = txn:get_var("txn.sc0_http_req_rate")
    
    if current_rate and current_rate > limits[content_type] then
        -- Rate limit excedido
        txn:set_var("txn.rate_limited", true)
        return true
    end
    
    return false
end

core.register_fetches("rate_limit", rate_limit)
EOF

    # Script de health check avanzado
    cat > "$CONFIG_DIR/haproxy/lua/health_check.lua" << 'EOF'
-- Advanced health checking
function advanced_health_check(txn)
    local server = txn.sf:srv_name()
    local backend = txn.sf:be_name()
    
    -- M√©tricas personalizadas de salud del servidor
    -- En producci√≥n, esto consultar√≠a m√©tricas reales
    
    local health_metrics = {
        cpu_usage = get_server_cpu(server),
        memory_usage = get_server_memory(server),
        response_time = get_server_response_time(server),
        error_rate = get_server_error_rate(server)
    }
    
    -- Calcular score de salud (0-100)
    local health_score = calculate_health_score(health_metrics)
    
    -- Ajustar peso del servidor basado en salud
    if health_score < 30 then
        -- Servidor con problemas, reducir peso
        return 10
    elseif health_score < 60 then
        -- Servidor con rendimiento medio
        return 50
    else
        -- Servidor saludable
        return 100
    end
end

function get_server_cpu(server)
    -- Stub - en producci√≥n obtener CPU real via API/SNMP
    return math.random(10, 90)
end

function get_server_memory(server)
    -- Stub - en producci√≥n obtener memoria real
    return math.random(30, 85)
end

function get_server_response_time(server)
    -- Stub - en producci√≥n obtener tiempo de respuesta real
    return math.random(50, 500)
end

function get_server_error_rate(server)
    -- Stub - en producci√≥n obtener tasa de error real
    return math.random(0, 5)
end

function calculate_health_score(metrics)
    local score = 100
    
    -- Penalizar por CPU alto
    if metrics.cpu_usage > 80 then
        score = score - 30
    elseif metrics.cpu_usage > 60 then
        score = score - 15
    end
    
    -- Penalizar por memoria alta
    if metrics.memory_usage > 90 then
        score = score - 25
    elseif metrics.memory_usage > 75 then
        score = score - 10
    end
    
    -- Penalizar por tiempo de respuesta alto
    if metrics.response_time > 1000 then
        score = score - 20
    elseif metrics.response_time > 500 then
        score = score - 10
    end
    
    -- Penalizar por tasa de error alta
    if metrics.error_rate > 5 then
        score = score - 15
    elseif metrics.error_rate > 2 then
        score = score - 5
    end
    
    return math.max(0, score)
end

core.register_fetches("advanced_health_check", advanced_health_check)
EOF

    log_success "HAProxy configurado para load balancing extremo"
}

# Configurar CDN Edge Locations distribuido
configure_cdn_edge_locations() {
    log_step "2" "Configurando CDN Edge Locations distribuido"
    
    create_secure_dir "$CONFIG_DIR/cdn"
    
    # Script de configuraci√≥n autom√°tica de edge locations
    cat > "$CONFIG_DIR/cdn/setup_edge_locations.sh" << 'EOF'
#!/bin/bash
# Configuraci√≥n autom√°tica de CDN Edge Locations

EDGE_REGIONS=(
    "us-east-1:New York:40.7128:-74.0060"
    "us-west-1:Los Angeles:34.0522:-118.2437"
    "eu-west-1:London:51.5074:-0.1278"
    "eu-central-1:Frankfurt:50.1109:8.6821"
    "ap-southeast-1:Singapore:1.3521:103.8198"
    "ap-northeast-1:Tokyo:35.6762:139.6503"
    "ap-south-1:Mumbai:19.0760:72.8777"
    "sa-east-1:S√£o Paulo:-23.5505:-46.6333"
    "af-south-1:Cape Town:-33.9249:18.4241"
    "me-south-1:Dubai:25.2048:55.2708"
    "ca-central-1:Toronto:43.6532:-79.3832"
    "au-southeast-1:Sydney:-33.8688:151.2093"
)

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# Configurar cada edge location
for region_data in "${EDGE_REGIONS[@]}"; do
    IFS=':' read -r region city lat lon <<< "$region_data"
    
    log "Configurando edge location: $region ($city)"
    
    # Crear configuraci√≥n de Nginx para esta edge location
    cat > "/etc/nginx/sites-available/edge-$region.conf" << EOF
server {
    listen 80;
    listen [::]:80;
    server_name edge-$region.example.com;
    
    # Logging espec√≠fico por regi√≥n
    access_log /var/log/nginx/edge-$region-access.log;
    error_log /var/log/nginx/edge-$region-error.log;
    
    # Cache local para esta edge location
    location / {
        proxy_cache edge_$region;
        proxy_cache_valid 200 301 302 1h;
        proxy_cache_valid 404 1m;
        proxy_cache_use_stale error timeout invalid_header updating;
        proxy_cache_lock on;
        proxy_cache_background_update on;
        
        # Headers de geolocalizaci√≥n
        add_header X-Edge-Location "$region";
        add_header X-Edge-City "$city";
        add_header X-Edge-Coordinates "$lat,$lon";
        add_header X-Cache-Status \$upstream_cache_status;
        
        # Proxy al origen con failover
        proxy_pass http://origin_servers;
        proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504;
        proxy_connect_timeout 5s;
        proxy_send_timeout 10s;
        proxy_read_timeout 30s;
        
        # Headers para el origen
        proxy_set_header Host \$host;
        proxy_set_header X-Real-IP \$remote_addr;
        proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
        proxy_set_header X-Edge-Region "$region";
        proxy_set_header X-Edge-Pop "$city";
    }
    
    # Health check endpoint
    location /edge-health {
        access_log off;
        return 200 '{"status":"healthy","region":"$region","city":"$city"}';
        add_header Content-Type application/json;
    }
}
EOF

    # Configurar cache path espec√≠fico
    mkdir -p "/var/cache/nginx/edge-$region"
    chown -R www-data:www-data "/var/cache/nginx/edge-$region"
    
    # Habilitar el sitio
    ln -sf "/etc/nginx/sites-available/edge-$region.conf" "/etc/nginx/sites-enabled/"
    
    log "Edge location $region configurado exitosamente"
done

# Configurar upstream de servidores origen
cat > "/etc/nginx/conf.d/origin_servers.conf" << 'EOF'
upstream origin_servers {
    # Servidores origen con diferentes pesos
    server 10.0.1.100:80 weight=3 max_fails=3 fail_timeout=30s;
    server 10.0.1.101:80 weight=3 max_fails=3 fail_timeout=30s;
    server 10.0.1.102:80 weight=2 max_fails=3 fail_timeout=30s;
    server 10.0.1.103:80 weight=2 max_fails=3 fail_timeout=30s;
    
    # Backup servers
    server 10.0.2.100:80 backup weight=1;
    server 10.0.2.101:80 backup weight=1;
    
    # Load balancing method
    least_conn;
    
    # Keep alive connections
    keepalive 32;
    keepalive_requests 100;
    keepalive_timeout 60s;
}
EOF

# Configurar cache zones
cat >> "/etc/nginx/nginx.conf" << 'EOF'

# Cache zones para cada edge location
EOF

for region_data in "${EDGE_REGIONS[@]}"; do
    IFS=':' read -r region city lat lon <<< "$region_data"
    cat >> "/etc/nginx/nginx.conf" << EOF
proxy_cache_path /var/cache/nginx/edge-$region levels=1:2 keys_zone=edge_$region:100m inactive=60m max_size=10g use_temp_path=off;
EOF
done

log "Todos los edge locations configurados. Reiniciando Nginx..."
nginx -t && systemctl reload nginx

log "CDN Edge Locations configurado exitosamente"
EOF

    chmod +x "$CONFIG_DIR/cdn/setup_edge_locations.sh"
    bash "$CONFIG_DIR/cdn/setup_edge_locations.sh"
    
    log_success "CDN Edge Locations distribuido configurado"
}

# Configurar sistema de auto-scaling geogr√°fico
configure_geographic_autoscaling() {
    log_step "3" "Configurando auto-scaling geogr√°fico"
    
    create_secure_dir "$CONFIG_DIR/autoscaling"
    
    # Script de auto-scaling inteligente
    cat > "$CONFIG_DIR/autoscaling/geographic_autoscaler.py" << 'EOF'
#!/usr/bin/env python3
"""
Sistema de Auto-scaling Geogr√°fico
Escala servidores autom√°ticamente basado en tr√°fico por regi√≥n
"""

import json
import time
import requests
import logging
import subprocess
import threading
from collections import defaultdict, deque
from datetime import datetime, timedelta

class GeographicAutoScaler:
    def __init__(self):
        self.regions = {
            'us-east-1': {'servers': 4, 'max_servers': 20, 'min_servers': 2},
            'us-west-1': {'servers': 4, 'max_servers': 20, 'min_servers': 2},
            'eu-west-1': {'servers': 3, 'max_servers': 15, 'min_servers': 2},
            'eu-central-1': {'servers': 3, 'max_servers': 15, 'min_servers': 2},
            'ap-southeast-1': {'servers': 2, 'max_servers': 10, 'min_servers': 1},
            'ap-northeast-1': {'servers': 2, 'max_servers': 10, 'min_servers': 1},
        }
        
        self.traffic_history = defaultdict(lambda: deque(maxlen=60))  # √öltimos 60 minutos
        self.scale_cooldown = defaultdict(int)  # Cooldown por regi√≥n
        
        # Thresholds
        self.scale_up_threshold = 80  # % CPU
        self.scale_down_threshold = 30  # % CPU
        self.traffic_threshold = 1000  # requests/min
        
        # Logging
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('/var/log/geographic_autoscaler.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def get_region_metrics(self, region):
        """Obtiene m√©tricas de una regi√≥n espec√≠fica"""
        try:
            # Obtener m√©tricas de HAProxy stats
            haproxy_stats = self.get_haproxy_stats()
            
            # Obtener m√©tricas espec√≠ficas de la regi√≥n
            cpu_usage = self.get_region_cpu_usage(region)
            memory_usage = self.get_region_memory_usage(region)
            request_rate = self.get_region_request_rate(region)
            response_time = self.get_region_response_time(region)
            error_rate = self.get_region_error_rate(region)
            
            return {
                'region': region,
                'cpu_usage': cpu_usage,
                'memory_usage': memory_usage,
                'request_rate': request_rate,
                'response_time': response_time,
                'error_rate': error_rate,
                'timestamp': time.time()
            }
        except Exception as e:
            self.logger.error(f"Error getting metrics for {region}: {str(e)}")
            return None
    
    def get_haproxy_stats(self):
        """Obtiene estad√≠sticas de HAProxy"""
        try:
            response = requests.get('http://localhost:8080/haproxy-stats;csv', 
                                  auth=('admin', 'password'), timeout=5)
            return response.text
        except Exception as e:
            self.logger.error(f"Error getting HAProxy stats: {str(e)}")
            return ""
    
    def get_region_cpu_usage(self, region):
        """Obtiene uso de CPU promedio de la regi√≥n"""
        try:
            # En producci√≥n, esto consultar√≠a m√©tricas reales de monitoring
            # Por ahora simulamos con datos aleatorios
            import random
            return random.uniform(20, 95)
        except:
            return 50.0
    
    def get_region_memory_usage(self, region):
        """Obtiene uso de memoria promedio de la regi√≥n"""
        try:
            import random
            return random.uniform(30, 90)
        except:
            return 60.0
    
    def get_region_request_rate(self, region):
        """Obtiene tasa de requests de la regi√≥n"""
        try:
            import random
            return random.randint(100, 5000)
        except:
            return 500
    
    def get_region_response_time(self, region):
        """Obtiene tiempo de respuesta promedio de la regi√≥n"""
        try:
            import random
            return random.uniform(50, 500)
        except:
            return 200.0
    
    def get_region_error_rate(self, region):
        """Obtiene tasa de errores de la regi√≥n"""
        try:
            import random
            return random.uniform(0, 5)
        except:
            return 1.0
    
    def should_scale_up(self, region, metrics):
        """Determina si debe escalar hacia arriba"""
        if not metrics:
            return False
        
        # Verificar cooldown
        if self.scale_cooldown[region] > time.time():
            return False
        
        # Verificar que no estemos en el m√°ximo
        if self.regions[region]['servers'] >= self.regions[region]['max_servers']:
            return False
        
        # Criterios para escalar hacia arriba
        conditions = [
            metrics['cpu_usage'] > self.scale_up_threshold,
            metrics['memory_usage'] > 85,
            metrics['request_rate'] > self.traffic_threshold,
            metrics['response_time'] > 1000,
            metrics['error_rate'] > 5
        ]
        
        # Necesitamos al menos 2 condiciones para escalar
        return sum(conditions) >= 2
    
    def should_scale_down(self, region, metrics):
        """Determina si debe escalar hacia abajo"""
        if not metrics:
            return False
        
        # Verificar cooldown
        if self.scale_cooldown[region] > time.time():
            return False
        
        # Verificar que no estemos en el m√≠nimo
        if self.regions[region]['servers'] <= self.regions[region]['min_servers']:
            return False
        
        # Criterios para escalar hacia abajo (m√°s conservador)
        conditions = [
            metrics['cpu_usage'] < self.scale_down_threshold,
            metrics['memory_usage'] < 50,
            metrics['request_rate'] < (self.traffic_threshold / 2),
            metrics['response_time'] < 200,
            metrics['error_rate'] < 1
        ]
        
        # Necesitamos todas las condiciones para escalar hacia abajo
        return all(conditions)
    
    def scale_up_region(self, region):
        """Escala una regi√≥n hacia arriba"""
        try:
            current_servers = self.regions[region]['servers']
            new_servers = min(current_servers + 2, self.regions[region]['max_servers'])
            
            self.logger.info(f"Scaling UP {region}: {current_servers} -> {new_servers}")
            
            # Comandos para crear nuevos servidores (adaptar seg√∫n infraestructura)
            for i in range(current_servers + 1, new_servers + 1):
                self.create_server_instance(region, i)
            
            self.regions[region]['servers'] = new_servers
            self.scale_cooldown[region] = time.time() + 300  # 5 minutos cooldown
            
            # Actualizar configuraci√≥n de HAProxy
            self.update_haproxy_config()
            
            self.logger.info(f"Successfully scaled UP {region} to {new_servers} servers")
            return True
            
        except Exception as e:
            self.logger.error(f"Error scaling up {region}: {str(e)}")
            return False
    
    def scale_down_region(self, region):
        """Escala una regi√≥n hacia abajo"""
        try:
            current_servers = self.regions[region]['servers']
            new_servers = max(current_servers - 1, self.regions[region]['min_servers'])
            
            self.logger.info(f"Scaling DOWN {region}: {current_servers} -> {new_servers}")
            
            # Comandos para remover servidores (graceful shutdown)
            for i in range(new_servers + 1, current_servers + 1):
                self.terminate_server_instance(region, i)
            
            self.regions[region]['servers'] = new_servers
            self.scale_cooldown[region] = time.time() + 600  # 10 minutos cooldown
            
            # Actualizar configuraci√≥n de HAProxy
            self.update_haproxy_config()
            
            self.logger.info(f"Successfully scaled DOWN {region} to {new_servers} servers")
            return True
            
        except Exception as e:
            self.logger.error(f"Error scaling down {region}: {str(e)}")
            return False
    
    def create_server_instance(self, region, instance_id):
        """Crea una nueva instancia de servidor"""
        self.logger.info(f"Creating server instance {region}-{instance_id}")
        
        # En producci√≥n, esto har√≠a llamadas a APIs de cloud providers
        # Por ahora simulamos con docker containers
        try:
            cmd = [
                'docker', 'run', '-d',
                '--name', f'server-{region}-{instance_id}',
                '--network', 'host',
                '-e', f'REGION={region}',
                '-e', f'INSTANCE_ID={instance_id}',
                'nginx:alpine'
            ]
            subprocess.run(cmd, check=True)
            self.logger.info(f"Server instance {region}-{instance_id} created successfully")
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Failed to create server instance {region}-{instance_id}: {str(e)}")
    
    def terminate_server_instance(self, region, instance_id):
        """Termina una instancia de servidor"""
        self.logger.info(f"Terminating server instance {region}-{instance_id}")
        
        try:
            # Graceful shutdown
            subprocess.run(['docker', 'stop', f'server-{region}-{instance_id}'], check=True)
            subprocess.run(['docker', 'rm', f'server-{region}-{instance_id}'], check=True)
            self.logger.info(f"Server instance {region}-{instance_id} terminated successfully")
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Failed to terminate server instance {region}-{instance_id}: {str(e)}")
    
    def update_haproxy_config(self):
        """Actualiza la configuraci√≥n de HAProxy con nuevos servidores"""
        try:
            self.logger.info("Updating HAProxy configuration")
            
            # Generar nueva configuraci√≥n basada en servidores actuales
            config_template = self.generate_haproxy_config()
            
            # Escribir nueva configuraci√≥n
            with open('/etc/haproxy/haproxy.cfg.new', 'w') as f:
                f.write(config_template)
            
            # Validar configuraci√≥n
            result = subprocess.run(['haproxy', '-f', '/etc/haproxy/haproxy.cfg.new', '-c'], 
                                  capture_output=True, text=True)
            
            if result.returncode == 0:
                # Configuraci√≥n v√°lida, aplicar cambios
                subprocess.run(['mv', '/etc/haproxy/haproxy.cfg.new', '/etc/haproxy/haproxy.cfg'])
                subprocess.run(['systemctl', 'reload', 'haproxy'])
                self.logger.info("HAProxy configuration updated successfully")
            else:
                self.logger.error(f"Invalid HAProxy configuration: {result.stderr}")
                
        except Exception as e:
            self.logger.error(f"Error updating HAProxy config: {str(e)}")
    
    def generate_haproxy_config(self):
        """Genera configuraci√≥n din√°mica de HAProxy"""
        # Template base de configuraci√≥n
        config = """
global
    daemon
    maxconn 1000000

defaults
    mode http
    timeout connect 5000ms
    timeout client 50000ms
    timeout server 50000ms

frontend http_frontend
    bind *:80
    bind *:443 ssl crt /etc/ssl/certs/
    default_backend web_servers

backend web_servers
    balance leastconn
    option httpchk GET /health

"""
        
        # Agregar servidores din√°micamente
        server_id = 1
        for region, config_data in self.regions.items():
            for i in range(1, config_data['servers'] + 1):
                config += f"    server {region}-{i} 10.0.{server_id}.10:80 check\n"
                server_id += 1
        
        return config
    
    def run_autoscaler(self):
        """Ejecuta el loop principal del autoscaler"""
        self.logger.info("Starting Geographic AutoScaler")
        
        while True:
            try:
                for region in self.regions.keys():
                    # Obtener m√©tricas de la regi√≥n
                    metrics = self.get_region_metrics(region)
                    
                    if metrics:
                        # Almacenar en historial
                        self.traffic_history[region].append(metrics)
                        
                        # Tomar decisiones de scaling
                        if self.should_scale_up(region, metrics):
                            self.scale_up_region(region)
                        elif self.should_scale_down(region, metrics):
                            self.scale_down_region(region)
                
                # Log del estado actual
                self.log_current_state()
                
                # Esperar 1 minuto antes del siguiente ciclo
                time.sleep(60)
                
            except Exception as e:
                self.logger.error(f"Error in autoscaler loop: {str(e)}")
                time.sleep(30)  # Espera menor en caso de error
    
    def log_current_state(self):
        """Log del estado actual de todas las regiones"""
        state = {
            'timestamp': datetime.now().isoformat(),
            'regions': {}
        }
        
        for region, config in self.regions.items():
            state['regions'][region] = {
                'servers': config['servers'],
                'max_servers': config['max_servers'],
                'min_servers': config['min_servers'],
                'cooldown_remaining': max(0, int(self.scale_cooldown[region] - time.time()))
            }
        
        self.logger.info(f"Current state: {json.dumps(state, indent=2)}")

def main():
    autoscaler = GeographicAutoScaler()
    autoscaler.run_autoscaler()

if __name__ == '__main__':
    main()
EOF

    chmod +x "$CONFIG_DIR/autoscaling/geographic_autoscaler.py"
    
    # Instalar dependencias
    pip3 install requests
    
    # Crear servicio systemd
    cat > "/etc/systemd/system/geographic-autoscaler.service" << 'EOF'
[Unit]
Description=Geographic AutoScaler Service
After=network.target haproxy.service

[Service]
Type=simple
User=root
Group=root
ExecStart=/usr/bin/python3 /etc/load-balancing-cdn/autoscaling/geographic_autoscaler.py
Restart=always
RestartSec=30

[Install]
WantedBy=multi-user.target
EOF

    systemctl daemon-reload
    systemctl enable geographic-autoscaler
    systemctl start geographic-autoscaler
    
    log_success "Auto-scaling geogr√°fico configurado"
}

# Configurar sistema de failover autom√°tico
configure_automatic_failover() {
    log_step "4" "Configurando sistema de failover autom√°tico"
    
    create_secure_dir "$CONFIG_DIR/failover"
    
    # Script de failover inteligente
    cat > "$CONFIG_DIR/failover/failover_manager.sh" << 'EOF'
#!/bin/bash

# Sistema de Failover Autom√°tico
# Detecta fallos y redirige tr√°fico autom√°ticamente

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
LOG_FILE="/var/log/failover_manager.log"
HEALTH_CHECK_INTERVAL=10
FAILOVER_THRESHOLD=3

# Servidores principales y backup
declare -A PRIMARY_SERVERS=(
    ["web"]="10.0.1.100:80"
    ["api"]="10.0.2.100:80"
    ["db"]="10.0.3.100:3306"
)

declare -A BACKUP_SERVERS=(
    ["web"]="10.0.1.200:80"
    ["api"]="10.0.2.200:80"
    ["db"]="10.0.3.200:3306"
)

declare -A HEALTH_STATUS=()
declare -A FAILURE_COUNT=()

log() {
    local level="$1"
    local message="$2"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] [$level] $message" | tee -a "$LOG_FILE"
}

# Health check para HTTP services
check_http_health() {
    local server="$1"
    local service="$2"
    
    if curl -s --connect-timeout 5 --max-time 10 "http://$server/health" >/dev/null 2>&1; then
        return 0
    else
        return 1
    fi
}

# Health check para base de datos
check_db_health() {
    local server="$1"
    local host="${server%%:*}"
    local port="${server##*:}"
    
    if timeout 5 bash -c "</dev/tcp/$host/$port" >/dev/null 2>&1; then
        return 0
    else
        return 1
    fi
}

# Ejecutar failover
execute_failover() {
    local service="$1"
    local from_server="$2"
    local to_server="$3"
    
    log "CRITICAL" "Executing failover for $service: $from_server -> $to_server"
    
    # Actualizar configuraci√≥n de HAProxy
    case "$service" in
        "web"|"api")
            update_haproxy_backend "$service" "$to_server"
            ;;
        "db")
            update_database_failover "$from_server" "$to_server"
            ;;
    esac
    
    # Notificar del failover
    send_failover_notification "$service" "$from_server" "$to_server"
    
    log "INFO" "Failover completed for $service"
}

# Actualizar backend de HAProxy
update_haproxy_backend() {
    local service="$1"
    local new_server="$2"
    
    # Deshabilitar servidor fallido
    echo "disable server ${service}_servers/${service}1" | socat stdio /var/run/haproxy.sock
    
    # Habilitar servidor backup
    echo "enable server ${service}_servers/${service}_backup1" | socat stdio /var/run/haproxy.sock
    
    log "INFO" "HAProxy backend updated for $service"
}

# Actualizar configuraci√≥n de base de datos
update_database_failover() {
    local failed_db="$1"
    local backup_db="$2"
    
    # Actualizar configuraci√≥n de aplicaci√≥n
    sed -i "s/$failed_db/$backup_db/g" /etc/database.conf
    
    # Reiniciar servicios que dependen de la DB
    systemctl restart php8.2-fpm
    
    log "INFO" "Database failover configuration updated"
}

# Enviar notificaci√≥n de failover
send_failover_notification() {
    local service="$1"
    local from_server="$2"
    local to_server="$3"
    
    local message="FAILOVER ALERT: $service service failed over from $from_server to $to_server at $(date)"
    
    # Log local
    log "ALERT" "$message"
    
    # Webhook (opcional)
    if [[ -n "${WEBHOOK_URL:-}" ]]; then
        curl -X POST "$WEBHOOK_URL" \
            -H "Content-Type: application/json" \
            -d "{\"text\":\"$message\",\"level\":\"critical\"}" \
            >/dev/null 2>&1
    fi
    
    # Email (opcional)
    if command -v mail >/dev/null 2>&1 && [[ -n "${ADMIN_EMAIL:-}" ]]; then
        echo "$message" | mail -s "Failover Alert - $service" "$ADMIN_EMAIL"
    fi
}

# Ejecutar health checks
run_health_checks() {
    log "DEBUG" "Starting health check cycle"
    
    # Check web servers
    for service in "${!PRIMARY_SERVERS[@]}"; do
        local primary="${PRIMARY_SERVERS[$service]}"
        local backup="${BACKUP_SERVERS[$service]}"
        
        log "DEBUG" "Checking $service primary server: $primary"
        
        case "$service" in
            "web"|"api")
                if check_http_health "$primary" "$service"; then
                    HEALTH_STATUS["$service"]="healthy"
                    FAILURE_COUNT["$service"]=0
                    log "DEBUG" "$service primary server is healthy"
                else
                    FAILURE_COUNT["$service"]=$((${FAILURE_COUNT["$service"]:-0} + 1))
                    log "WARNING" "$service primary server check failed (${FAILURE_COUNT[$service]}/$FAILOVER_THRESHOLD)"
                    
                    if [[ ${FAILURE_COUNT["$service"]} -ge $FAILOVER_THRESHOLD ]]; then
                        if [[ "${HEALTH_STATUS[$service]}" != "failed" ]]; then
                            HEALTH_STATUS["$service"]="failed"
                            execute_failover "$service" "$primary" "$backup"
                        fi
                    fi
                fi
                ;;
            "db")
                if check_db_health "$primary"; then
                    HEALTH_STATUS["$service"]="healthy"
                    FAILURE_COUNT["$service"]=0
                    log "DEBUG" "$service primary server is healthy"
                else
                    FAILURE_COUNT["$service"]=$((${FAILURE_COUNT["$service"]:-0} + 1))
                    log "WARNING" "$service primary server check failed (${FAILURE_COUNT[$service]}/$FAILOVER_THRESHOLD)"
                    
                    if [[ ${FAILURE_COUNT["$service"]} -ge $FAILOVER_THRESHOLD ]]; then
                        if [[ "${HEALTH_STATUS[$service]}" != "failed" ]]; then
                            HEALTH_STATUS["$service"]="failed"
                            execute_failover "$service" "$primary" "$backup"
                        fi
                    fi
                fi
                ;;
        esac
    done
    
    log "DEBUG" "Health check cycle completed"
}

# Funci√≥n principal
main() {
    log "INFO" "Starting Failover Manager"
    
    # Inicializar contadores
    for service in "${!PRIMARY_SERVERS[@]}"; do
        FAILURE_COUNT["$service"]=0
        HEALTH_STATUS["$service"]="unknown"
    done
    
    # Loop principal
    while true; do
        run_health_checks
        sleep "$HEALTH_CHECK_INTERVAL"
    done
}

# Trap para cleanup
trap 'log "INFO" "Failover Manager stopping"; exit 0' TERM INT

# Ejecutar funci√≥n principal
main "$@"
EOF

    chmod +x "$CONFIG_DIR/failover/failover_manager.sh"
    
    # Crear servicio systemd
    cat > "/etc/systemd/system/failover-manager.service" << 'EOF'
[Unit]
Description=Automatic Failover Manager
After=network.target haproxy.service

[Service]
Type=simple
User=root
Group=root
ExecStart=/etc/load-balancing-cdn/failover/failover_manager.sh
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
EOF

    systemctl daemon-reload
    systemctl enable failover-manager
    systemctl start failover-manager
    
    log_success "Sistema de failover autom√°tico configurado"
}

# Funci√≥n principal
main() {
    show_banner
    
    log_info "Iniciando configuraci√≥n del sistema de Load Balancing y CDN autom√°tico"
    
    # Verificar permisos de root
    check_root || show_error "Este script requiere permisos de root"
    
    # Crear directorios necesarios
    create_secure_dir "$CONFIG_DIR"
    
    # Ejecutar configuraciones
    configure_haproxy_extreme
    configure_cdn_edge_locations
    configure_geographic_autoscaling
    configure_automatic_failover
    
    echo
    log_success "üéâ SISTEMA DE LOAD BALANCING Y CDN AUTOM√ÅTICO CONFIGURADO"
    echo
    echo -e "${BOLD}${GREEN}üåê COMPONENTES INSTALADOS:${NC}"
    echo "   ‚ö° HAProxy Load Balancer - 1M+ conexiones concurrentes"
    echo "   üåç CDN Edge Locations - $EDGE_LOCATIONS ubicaciones globales"
    echo "   üìà Auto-scaling geogr√°fico - Escalado inteligente por regi√≥n"
    echo "   üîÑ Failover autom√°tico - <3 segundos de recuperaci√≥n"
    echo "   üìä Monitoreo en tiempo real - M√©tricas por regi√≥n"
    echo
    echo -e "${BOLD}${GREEN}üéØ CAPACIDADES:${NC}"
    echo "   üöÄ >10M requests/minuto"
    echo "   üíæ >100TB/d√≠a transferencia"
    echo "   üåé Latencia <50ms global"
    echo "   ‚è±Ô∏è 99.99% uptime"
    echo "   üìà Auto-scaling din√°mico"
    echo
    echo -e "${BOLD}${CYAN}üîß HERRAMIENTAS DE MONITOREO:${NC}"
    echo "   üìä HAProxy Stats: http://localhost:8080/haproxy-stats"
    echo "   üìà AutoScaler Logs: tail -f /var/log/geographic_autoscaler.log"
    echo "   üîÑ Failover Logs: tail -f /var/log/failover_manager.log"
    echo "   üåê Edge Health: curl http://edge-us-east-1.example.com/edge-health"
    echo
    echo -e "${BOLD}${YELLOW}‚ö†Ô∏è PR√ìXIMOS PASOS:${NC}"
    echo "   1. Configurar DNS para edge locations"
    echo "   2. Configurar certificados SSL/TLS"
    echo "   3. Ajustar thresholds de auto-scaling"
    echo "   4. Configurar notificaciones de alertas"
    echo "   5. Realizar pruebas de failover"
    echo
}

# Ejecutar funci√≥n principal
main "$@"